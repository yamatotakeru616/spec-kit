{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook E — 05_create_training_data.ipynb (Prepare Dataset)\n",
                "\n",
                "This notebook loads annotated point clouds (or labeled folders) and generates a training dataset (features + labels) for the classifier.\n",
                "\n",
                "## Concepts\n",
                "- **Features**: Geometric and color features extracted from points (XYZ, Normals, Colors, Height).\n",
                "- **Labels**: Ground truth class derived from `.las` classification or folder structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell E0 — Install dependencies\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "def install_packages(packages):\n",
                "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n",
                "\n",
                "try:\n",
                "    import open3d\n",
                "    import laspy\n",
                "except ImportError:\n",
                "    print(\"Installing dependencies...\")\n",
                "    install_packages(['numpy', 'open3d', 'trimesh', 'laspy', 'scipy', 'onnxruntime', 'numba', 'py-vox-io'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell E1 — Mount Drive & Setup\n",
                "from google.colab import drive\n",
                "import os\n",
                "import sys\n",
                "import shutil\n",
                "import subprocess\n",
                "import importlib\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "BASE = \"/content/drive/MyDrive/voxel_engine\"\n",
                "REPO_DIR = \"/content/spec-kit\"\n",
                "SRC_DIR = os.path.join(REPO_DIR, \"src\")\n",
                "\n",
                "# --- SELF-HEALING SETUP ---\n",
                "# Check if loader.py exists. If not, re-clone.\n",
                "loader_path = os.path.join(SRC_DIR, \"loader.py\")\n",
                "\n",
                "if not os.path.exists(loader_path):\n",
                "    print(\"Dependencies missing or corrupted. Re-cloning repository...\")\n",
                "    if os.path.exists(REPO_DIR):\n",
                "        shutil.rmtree(REPO_DIR)\n",
                "    \n",
                "    # Clone repo using subprocess to avoid syntax errors in IDEs\n",
                "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/yamatotakeru616/spec-kit.git\", REPO_DIR])\n",
                "    \n",
                "    # Install requirements\n",
                "    req_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
                "    if os.path.exists(req_path):\n",
                "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", req_path])\n",
                "else:\n",
                "    print(\"Repository found.\")\n",
                "\n",
                "# Add to path\n",
                "if SRC_DIR not in sys.path:\n",
                "    sys.path.append(SRC_DIR)\n",
                "    print(f\"Added {SRC_DIR} to sys.path\")\n",
                "\n",
                "# Reload modules to ensure we have latest version\n",
                "try:\n",
                "    import loader, classify, utils\n",
                "    import numpy as np\n",
                "    importlib.reload(loader)\n",
                "    importlib.reload(classify)\n",
                "    importlib.reload(utils)\n",
                "    print(\"Imports successful!\")\n",
                "except ImportError as e:\n",
                "    print(\"CRITICAL ERROR: Could not import modules even after clone.\")\n",
                "    # Fallback: try to see what is in the directory\n",
                "    print(f\"Contents of {SRC_DIR}:\", os.listdir(SRC_DIR) if os.path.exists(SRC_DIR) else \"Directory not found\")\n",
                "    raise e\n",
                "\n",
                "INPUT_DIR = os.path.join(BASE, \"input\")\n",
                "TRAIN_DIR = os.path.join(BASE, \"training_data\")\n",
                "\n",
                "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
                "print(\"Ready to process data in:\", INPUT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell E2 — Define Feature Extraction Helper\n",
                "\n",
                "def process_file(path, label_override=None):\n",
                "    \"\"\"\n",
                "    Loads a file, computes features, and returns (features, labels).\n",
                "    If label_override is provided, forces all points to have that label.\n",
                "    Otherwise, tries to read labels from file (LAS classification).\n",
                "    \"\"\"\n",
                "    print(f\"Processing {os.path.basename(path)}...\")\n",
                "    \n",
                "    # Load with upgraded loader that supports labels\n",
                "    # Note: If loader.py wasn't updated in previous steps, this might fail to get labels if not using folder mode.\n",
                "    try:\n",
                "        if hasattr(loader, 'load_annotated_pointcloud'):\n",
                "            pts, cols, file_labels = loader.load_annotated_pointcloud(path)\n",
                "        else:\n",
                "            # Fallback if old loader\n",
                "            pts, cols = loader.load_pointcloud(path)\n",
                "            file_labels = None\n",
                "    except Exception as e:\n",
                "        print(f\"Failed to load {path}: {e}\")\n",
                "        return None, None\n",
                "\n",
                "    # Compute features\n",
                "    # compute_features(points, colors=None, normals=None)\n",
                "    feats = classify.compute_features(pts, colors=cols)\n",
                "    \n",
                "    # Determine Labels\n",
                "    target_labels = None\n",
                "    \n",
                "    if label_override is not None:\n",
                "        # Create full array of this label\n",
                "        target_labels = np.full(pts.shape[0], label_override, dtype=np.uint8)\n",
                "    elif file_labels is not None:\n",
                "        target_labels = file_labels\n",
                "    else:\n",
                "        print(f\"Warning: No labels found for {path} and no override provided. Skipping labels.\")\n",
                "    \n",
                "    return feats, target_labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell E3 — Process Dataset (Auto-Detect Mode)\n",
                "    \n",
                "print(f\"--- Checking Input Directory: {INPUT_DIR} ---\")\n",
                "if os.path.exists(INPUT_DIR):\n",
                "    contents = os.listdir(INPUT_DIR)\n",
                "    print(f\"Contents of input/: {contents}\")\n",
                "else:\n",
                "    print(f\"Error: Input directory {INPUT_DIR} not found.\")\n",
                "    contents = []\n",
                "\n",
                "all_feats = []\n",
                "all_labels = []\n",
                "\n",
                "# Define your class mapping here if using folders\n",
                "CLASS_MAP = {\n",
                "    \"ground\": 1,\n",
                "    \"vegetation\": 2,\n",
                "    \"building\": 3,\n",
                "    \"vehicle\": 4,\n",
                "    \"other\": 5  # Added example\n",
                "}\n",
                "\n",
                "# Auto-detect mode if possible, or default to folder\n",
                "# logic: if any class folder exists, use folder mode. Else if any laz/las file in root, use file mode.\n",
                "\n",
                "scan_mode = \"auto\" # \"folder\", \"file\", or \"auto\"\n",
                "\n",
                "if scan_mode == \"auto\":\n",
                "    has_class_folders = any(os.path.exists(os.path.join(INPUT_DIR, k)) for k in CLASS_MAP.keys())\n",
                "    has_root_files = any(f.lower().endswith(('.las', '.laz')) for f in contents)\n",
                "    \n",
                "    if has_class_folders:\n",
                "        scan_mode = \"folder\"\n",
                "        print(\"Auto-mode: Detected class folders. Using 'folder' mode.\")\n",
                "    elif has_root_files:\n",
                "        scan_mode = \"file\"\n",
                "        print(\"Auto-mode: Detected point cloud files in root. Using 'file' mode.\")\n",
                "    else:\n",
                "        print(\"Auto-mode: Could not detect valid data structure. Defaulting to 'folder'.\")\n",
                "        scan_mode = \"folder\"\n",
                "\n",
                "if scan_mode == \"folder\":\n",
                "    print(f\"Scanning for folders: {list(CLASS_MAP.keys())} ...\")\n",
                "    found_any_folder = False\n",
                "    for folder_name, label_id in CLASS_MAP.items():\n",
                "        folder_path = os.path.join(INPUT_DIR, folder_name)\n",
                "        if not os.path.exists(folder_path): \n",
                "            # print(f\"  (Folder '{folder_name}' not found, skipping)\")\n",
                "            continue\n",
                "        \n",
                "        found_any_folder = True\n",
                "        files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.las', '.laz', '.ply', '.obj'))]\n",
                "        print(f\"Found {len(files)} files for class '{folder_name}' (ID: {label_id})\")\n",
                "        \n",
                "        for f in files:\n",
                "            fp = os.path.join(folder_path, f)\n",
                "            f_feats, f_lbls = process_file(fp, label_override=label_id)\n",
                "            if f_feats is not None and f_lbls is not None:\n",
                "                all_feats.append(f_feats)\n",
                "                all_labels.append(f_lbls)\n",
                "    \n",
                "    if not found_any_folder:\n",
                "        print(\"Warning: No class folders found matching CLASS_MAP keys.\")\n",
                "        print(\"Please create folders like 'ground', 'building' inside 'input/' and put files there.\")\n",
                "        print(\"OR, if you have a single .las file with classification, ensure it is in 'input/' and re-run.\")\n",
                "\n",
                "# Cell E4 — Process Dataset (Option B: Single file with embedded labels)\n",
                "if scan_mode == \"file\":\n",
                "     files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.las', '.laz'))]\n",
                "     print(f\"Scanning files in root: {files}\")\n",
                "     \n",
                "     if len(files) == 0:\n",
                "         print(\"Error: scan_mode is 'file' but no .las/.laz files found in input/.\")\n",
                "     \n",
                "     for f in files:\n",
                "         fp = os.path.join(INPUT_DIR, f)\n",
                "         f_feats, f_lbls = process_file(fp)\n",
                "         if f_feats is not None and f_lbls is not None:\n",
                "            all_feats.append(f_feats)\n",
                "            all_labels.append(f_lbls)\n",
                "            \n",
                "if len(all_feats) > 0:\n",
                "    X = np.vstack(all_feats)\n",
                "    y = np.concatenate(all_labels)\n",
                "    print(f\"\\n=== SUMMARY ===\")\n",
                "    print(f\"Total Training Data: {X.shape[0]} points\")\n",
                "    print(f\"Features: {X.shape[1]}\")\n",
                "    print(f\"Classes found: {np.unique(y)}\")\n",
                "else:\n",
                "    print(\"\\n=== RESULT: NO DATA GENERATED ===\")\n",
                "    print(\"Reasons match empty output:\")\n",
                "    print(\"1. No files found in the expected locations.\")\n",
                "    print(\"2. Files found but failed to load.\")\n",
                "    print(\"3. Files loaded but classification/labels were missing (and no override provided).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell E5 — Save Training Data\n",
                "if len(all_feats) > 0:\n",
                "    save_path = os.path.join(TRAIN_DIR, \"training_data.npz\")\n",
                "    np.savez_compressed(save_path, X=X, y=y)\n",
                "    print(f\"Saved dataset to {save_path}\")\n",
                "    \n",
                "    # Optional: Save a small sample for verification\n",
                "    # sample_idx = np.random.choice(len(X), min(10000, len(X)), replace=False)\n",
                "    # np.savez(os.path.join(TRAIN_DIR, \"sample_data.npz\"), X=X[sample_idx], y=y[sample_idx])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}